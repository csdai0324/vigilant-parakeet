{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:49:24.137420Z",
     "start_time": "2020-05-18T08:49:24.130793Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time \n",
    "import PIL\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:49:24.322824Z",
     "start_time": "2020-05-18T08:49:24.312555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Info\n",
      "    PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "CPU Info\n",
      "    PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "\n",
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "def test_device():\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    cpus = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "    gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "    print('GPU Info')\n",
    "    for gpu in gpus:\n",
    "        print('   ', gpu)\n",
    "    print('CPU Info')\n",
    "    for cpu in cpus:\n",
    "        print('   ', cpu)\n",
    "    \n",
    "    print()\n",
    "    if gpus:\n",
    "        try:\n",
    "            tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "            tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "        \n",
    "test_device()\n",
    "tf.keras.backend.clear_session() \n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:49:24.491827Z",
     "start_time": "2020-05-18T08:49:24.488789Z"
    }
   },
   "outputs": [],
   "source": [
    "data_root_orig = './data/sep_data/train'\n",
    "val_data_root_orig = './data/sep_data/validation'\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "epoch = 50\n",
    "channel_size = 1\n",
    "ver = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:49:24.663413Z",
     "start_time": "2020-05-18T08:49:24.655336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/sep_data/train [PosixPath('data/sep_data/train/2'), PosixPath('data/sep_data/train/0'), PosixPath('data/sep_data/train/5'), PosixPath('data/sep_data/train/3'), PosixPath('data/sep_data/train/4'), PosixPath('data/sep_data/train/1')]\n",
      "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}\n",
      "data/sep_data/validation [PosixPath('data/sep_data/validation/2'), PosixPath('data/sep_data/validation/0'), PosixPath('data/sep_data/validation/5'), PosixPath('data/sep_data/validation/3'), PosixPath('data/sep_data/validation/4'), PosixPath('data/sep_data/validation/1')]\n",
      "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}\n"
     ]
    }
   ],
   "source": [
    "data_root = pathlib.Path(data_root_orig)\n",
    "print(data_root, list(data_root.iterdir()))\n",
    "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
    "print(label_to_index)\n",
    "\n",
    "val_data_root = pathlib.Path(val_data_root_orig)\n",
    "print(val_data_root, list(val_data_root.iterdir()))\n",
    "val_label_names = sorted(item.name for item in val_data_root.glob('*/') if item.is_dir())\n",
    "val_label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
    "print(val_label_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:49:24.983535Z",
     "start_time": "2020-05-18T08:49:24.848269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image count      : 13950\n",
      "Validation image count : 513\n"
     ]
    }
   ],
   "source": [
    "all_image_paths = list(data_root.glob('*/*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "random.shuffle(all_image_paths)\n",
    "image_count = len(all_image_paths)\n",
    "all_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in all_image_paths]\n",
    "\n",
    "val_all_image_paths = list(val_data_root.glob('*/*'))\n",
    "val_all_image_paths = [str(path) for path in val_all_image_paths]\n",
    "val_image_count = len(val_all_image_paths)\n",
    "random.shuffle(val_all_image_paths)\n",
    "val_all_image_labels = [label_to_index[pathlib.Path(path).parent.name] for path in val_all_image_paths]\n",
    "\n",
    "print(\"Train image count      : {}\".format(image_count))\n",
    "print(\"Validation image count : {}\".format(val_image_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:49:25.662729Z",
     "start_time": "2020-05-18T08:49:25.657857Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=1)\n",
    "    image = tf.image.resize(image, [img_size, img_size])\n",
    "    image /= 255.0 \n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)\n",
    "\n",
    "def load_and_preprocess_from_path_label(path, label):\n",
    "    return load_and_preprocess_image(path), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:49:26.680918Z",
     "start_time": "2020-05-18T08:49:26.473138Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))\n",
    "image_label_ds = ds.map(load_and_preprocess_from_path_label)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_all_image_paths, val_all_image_labels))\n",
    "val_image_label_ds = val_ds.map(load_and_preprocess_from_path_label)\n",
    "\n",
    "steps_per_epoch = int(image_count / batch_size)\n",
    "val_steps_per_epoch = int(val_image_count / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:49:27.166906Z",
     "start_time": "2020-05-18T08:49:27.160759Z"
    }
   },
   "outputs": [],
   "source": [
    " default_timeit_steps = 2*steps_per_epoch+1\n",
    "\n",
    "def timeit(ds, steps=default_timeit_steps):\n",
    "    overall_start = time.time()\n",
    "    it = iter(ds.take(steps+1))\n",
    "    next(it)\n",
    "\n",
    "    start = time.time()\n",
    "    for i,(images,labels) in enumerate(it):\n",
    "        if i%10 == 0:\n",
    "            print('.',end='')\n",
    "            \n",
    "    end = time.time()\n",
    "\n",
    "    duration = end-start\n",
    "    print(\"{} batches: {} s\".format(steps, duration))\n",
    "    print(\"{:0.5f} Images/s\".format(batch_size*steps/duration))\n",
    "    print(\"Total time: {}s\".format(end-overall_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:50:02.318849Z",
     "start_time": "2020-05-18T08:49:27.624951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................871 batches: 0.6510493755340576 s\n",
      "42810.88508 Images/s\n",
      "Total time: 34.6869912147522s\n"
     ]
    }
   ],
   "source": [
    "ds = image_label_ds.cache()\n",
    "ds = ds.shuffle(buffer_size=image_count)\n",
    "ds = ds.repeat()\n",
    "ds = ds.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "timeit(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:50:03.504897Z",
     "start_time": "2020-05-18T08:50:02.321144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..33 batches: 1.0953161716461182 s\n",
      "964.10518 Images/s\n",
      "Total time: 1.1794078350067139s\n"
     ]
    }
   ],
   "source": [
    "val_ds = val_image_label_ds.cache()\n",
    "val_ds = val_ds.batch(batch_size).prefetch(buffer_size=val_image_count)\n",
    "timeit(val_ds, 2*val_steps_per_epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:50:07.575083Z",
     "start_time": "2020-05-18T08:50:07.520353Z"
    }
   },
   "outputs": [],
   "source": [
    "def change_range(image, label):\n",
    "    return 2*image-1, tf.one_hot(label, depth=6)\n",
    "keras_ds = ds.map(change_range)\n",
    "keras_val_ds = val_ds.map(change_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:50:09.143309Z",
     "start_time": "2020-05-18T08:50:07.793182Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session() \n",
    "mobile_net = tf.keras.applications.MobileNetV2(input_shape=(img_size, img_size, channel_size), \n",
    "                                               weights=None, include_top=False)\n",
    "mobile_net.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:50:10.033372Z",
     "start_time": "2020-05-18T08:50:09.144720Z"
    }
   },
   "outputs": [],
   "source": [
    "model_mobile = tf.keras.Sequential([\n",
    "    mobile_net,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(6)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-18T08:50:09.614Z"
    }
   },
   "outputs": [],
   "source": [
    "input1 = tf.keras.layers.Input(shape=(img_size, img_size, 1))\n",
    "mergedOut1 = tf.keras.layers.average([mobile_net(input1), mobile_net(input1)])\n",
    "model1 = tf.keras.models.Model(inputs=input1, outputs=mergedOut1)\n",
    "model_2_mobile = tf.keras.Sequential([\n",
    "    model1,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(6),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:10:43.318557Z",
     "start_time": "2020-05-18T08:10:43.315991Z"
    }
   },
   "outputs": [],
   "source": [
    "path = './model/checkpoints_{}_{}_{}_{}'.format(img_size, batch_size, 888, 0)\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                        monitor='val_loss',\n",
    "                                        verbose=0, save_best_only=True,\n",
    "                                        save_weights_only=False, mode='min', save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:42:14.825804Z",
     "start_time": "2020-05-18T08:10:45.753853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.4531 - accuracy: 0.9083INFO:tensorflow:Assets written to: ./model/checkpoints_224_32_888_0/assets\n",
      "431/431 [==============================] - 77s 179ms/step - loss: 0.4531 - accuracy: 0.9083 - val_loss: 0.1155 - val_accuracy: 0.9917\n",
      "Epoch 2/30\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9986INFO:tensorflow:Assets written to: ./model/checkpoints_224_32_888_0/assets\n",
      "431/431 [==============================] - 79s 182ms/step - loss: 0.0468 - accuracy: 0.9986 - val_loss: 0.0595 - val_accuracy: 0.9917\n",
      "Epoch 3/30\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9993INFO:tensorflow:Assets written to: ./model/checkpoints_224_32_888_0/assets\n",
      "431/431 [==============================] - 77s 179ms/step - loss: 0.0189 - accuracy: 0.9993 - val_loss: 0.0422 - val_accuracy: 0.9937\n",
      "Epoch 4/30\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9995INFO:tensorflow:Assets written to: ./model/checkpoints_224_32_888_0/assets\n",
      "431/431 [==============================] - 80s 186ms/step - loss: 0.0104 - accuracy: 0.9995 - val_loss: 0.0312 - val_accuracy: 0.9917\n",
      "Epoch 5/30\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9997INFO:tensorflow:Assets written to: ./model/checkpoints_224_32_888_0/assets\n",
      "431/431 [==============================] - 78s 181ms/step - loss: 0.0071 - accuracy: 0.9997 - val_loss: 0.0308 - val_accuracy: 0.9917\n",
      "Epoch 6/30\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9999INFO:tensorflow:Assets written to: ./model/checkpoints_224_32_888_0/assets\n",
      "431/431 [==============================] - 82s 190ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.0277 - val_accuracy: 0.9937\n",
      "Epoch 7/30\n",
      "431/431 [==============================] - 53s 122ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.0283 - val_accuracy: 0.9937\n",
      "Epoch 8/30\n",
      "431/431 [==============================] - 54s 125ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0300 - val_accuracy: 0.9937\n",
      "Epoch 9/30\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9999INFO:tensorflow:Assets written to: ./model/checkpoints_224_32_888_0/assets\n",
      "431/431 [==============================] - 78s 181ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0269 - val_accuracy: 0.9937\n",
      "Epoch 10/30\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000INFO:tensorflow:Assets written to: ./model/checkpoints_224_32_888_0/assets\n",
      "431/431 [==============================] - 83s 193ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9937\n",
      "Epoch 11/30\n",
      "431/431 [==============================] - 55s 127ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9917\n",
      "Epoch 12/30\n",
      "431/431 [==============================] - 54s 124ms/step - loss: 8.8982e-04 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9937\n",
      "Epoch 13/30\n",
      "431/431 [==============================] - 54s 124ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0307 - val_accuracy: 0.9937\n",
      "Epoch 14/30\n",
      "431/431 [==============================] - 54s 125ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0331 - val_accuracy: 0.9937\n",
      "Epoch 15/30\n",
      "431/431 [==============================] - 54s 125ms/step - loss: 8.6833e-04 - accuracy: 0.9999 - val_loss: 0.0350 - val_accuracy: 0.9937\n",
      "Epoch 16/30\n",
      "431/431 [==============================] - 54s 125ms/step - loss: 5.9759e-04 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9937\n",
      "Epoch 17/30\n",
      "431/431 [==============================] - ETA: 0s - loss: 4.7575e-04 - accuracy: 1.0000INFO:tensorflow:Assets written to: ./model/checkpoints_224_32_888_0/assets\n",
      "431/431 [==============================] - 80s 186ms/step - loss: 4.7575e-04 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9937\n",
      "Epoch 18/30\n",
      "431/431 [==============================] - ETA: 0s - loss: 5.5539e-04 - accuracy: 0.9999INFO:tensorflow:Assets written to: ./model/checkpoints_224_32_888_0/assets\n",
      "431/431 [==============================] - 86s 198ms/step - loss: 5.5539e-04 - accuracy: 0.9999 - val_loss: 0.0246 - val_accuracy: 0.9937\n",
      "Epoch 19/30\n",
      "431/431 [==============================] - 54s 125ms/step - loss: 3.2061e-04 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9937\n",
      "Epoch 20/30\n",
      "431/431 [==============================] - 55s 127ms/step - loss: 8.9019e-04 - accuracy: 0.9999 - val_loss: 0.0264 - val_accuracy: 0.9937\n",
      "Epoch 21/30\n",
      "431/431 [==============================] - 54s 124ms/step - loss: 9.8523e-04 - accuracy: 0.9999 - val_loss: 0.0295 - val_accuracy: 0.9958\n",
      "Epoch 22/30\n",
      "431/431 [==============================] - 55s 127ms/step - loss: 3.1741e-04 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9937\n",
      "Epoch 23/30\n",
      "431/431 [==============================] - 54s 126ms/step - loss: 4.5081e-04 - accuracy: 0.9999 - val_loss: 0.0400 - val_accuracy: 0.9937\n",
      "Epoch 24/30\n",
      "431/431 [==============================] - 55s 127ms/step - loss: 2.2108e-04 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9937\n",
      "Epoch 25/30\n",
      "431/431 [==============================] - 54s 126ms/step - loss: 2.5915e-04 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9937\n",
      "Epoch 26/30\n",
      "431/431 [==============================] - 55s 128ms/step - loss: 8.5413e-04 - accuracy: 0.9999 - val_loss: 0.0425 - val_accuracy: 0.9937\n",
      "Epoch 27/30\n",
      "431/431 [==============================] - 55s 127ms/step - loss: 1.6869e-04 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9937\n",
      "Epoch 28/30\n",
      "431/431 [==============================] - 54s 125ms/step - loss: 2.3093e-04 - accuracy: 0.9999 - val_loss: 0.0363 - val_accuracy: 0.9937\n",
      "Epoch 29/30\n",
      "431/431 [==============================] - 55s 127ms/step - loss: 9.6944e-04 - accuracy: 0.9996 - val_loss: 0.0324 - val_accuracy: 0.9937\n",
      "Epoch 30/30\n",
      "431/431 [==============================] - 54s 125ms/step - loss: 1.7612e-04 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9937\n"
     ]
    }
   ],
   "source": [
    "model_ = model_mobile\n",
    "model_.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_.fit(keras_ds, epochs=30, steps_per_epoch=steps_per_epoch, \n",
    "          validation_data=keras_val_ds, validation_steps=val_steps_per_epoch,\n",
    "          callbacks=[cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T08:49:19.497256Z",
     "start_time": "2020-05-18T08:49:19.492511Z"
    }
   },
   "outputs": [],
   "source": [
    "log_ = 'log.log'\n",
    "with open(log_, 'a+') as log:\n",
    "    model_name = (path.split('/')[-1])\n",
    "    valloss = min(history.history['val_loss'])\n",
    "    idx = history.history['val_loss'].index(valloss)\n",
    "    valacc = history.history['val_accuracy'][idx]\n",
    "    log.write(\"{}, {}, {}\\n\".format(model_name, valloss, valacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
